# Supabase Deployment Guide

This project can run fully offline using the legacy local providers, but the production target is Supabase for authentication, storage, and Postgres (with `pgvector`). The steps below assume you already have a Supabase project created.

## 1. Supabase Configuration

### Database
- Copy the Postgres connection string from the Supabase dashboard (`Project settings → Database → Connection string → URI`).
- Append a database name if you want to isolate environments (e.g. `/scopedoc`).
- The backend automatically adds `sslmode=require` when Supabase is detected, so you do **not** need to edit the DSN manually.

### Storage
- Create a bucket (default name: `scope-docs`).
- Enable **public** access for now. Access control relies on signed URLs generated by the backend; add RLS policies once you are ready for multi-tenant usage.

### Authentication
- Enable email/password sign-in (no magic link required).
- Grab the **anon** key and the **service role** key from `Project settings → API`.
- Optional: restrict the JWT audience if you want to separate client applications (default is `authenticated`).

## 2. Environment Variables

Copy `server/env.example` to `server/.env` and fill in the placeholders. Do the same for `frontend/env.local.example` → `frontend/.env.local`.

```bash
cp server/env.example server/.env
cp frontend/env.local.example frontend/.env.local
```

### Backend (`server/.env`)
- `DATABASE_DSN` – Supabase Postgres URI
- `AUTH_PROVIDER=supabase`
- `STORAGE_PROVIDER=supabase`
- `SUPABASE_URL` – e.g. `https://xyzcompany.supabase.co`
- `SUPABASE_SERVICE_ROLE_KEY` – **keep secret**
- `SUPABASE_BUCKET` – defaults to `scope-docs`
- `ARTIFACT_URL_EXPIRY_SECONDS` – signed URL lifetime for downloads (default `3600`)
- `SESSION_SECRET` – random string for legacy cookie fallback
- Optional integrations: `PERPLEXITY_API_KEY`, `ANTHROPIC_API_KEY`, `ENABLE_WEB_RESEARCH`

### Frontend (`frontend/.env.local`)
- `NEXT_PUBLIC_SUPABASE_URL`
- `NEXT_PUBLIC_SUPABASE_ANON_KEY`
- `NEXT_PUBLIC_API_BASE_URL=/backend` (assuming Nginx proxies FastAPI at `/backend`)
- Optional: `NEXT_PUBLIC_SESSION_COOKIE_NAME` if you rename the legacy cookie.

## 3. Database Migrations

Use Alembic to create the schema in Supabase:

```bash
cd server
alembic upgrade head
```

The initial migration creates:
- `users`, `projects`, `project_files`, `runs`, `run_steps`, `artifacts`, `scope_embeddings`
- Extensions: `pgcrypto` and `vector`

Re-run `alembic revision --autogenerate` for schema changes, then `alembic upgrade head` as part of deployment. The app reads provider flags at startup, so you can still run locally with `AUTH_PROVIDER=local` and `STORAGE_PROVIDER=local` (files will be stored under `data/projects`).

## 4. Local Development

```bash
# Backend
cd server
pip install -r ../requirements.txt
uvicorn server.api:app --reload --host 0.0.0.0 --port 8000

# Frontend
cd ../frontend
npm install
npm run dev -- --hostname 0.0.0.0 --port 3000
```

The frontend proxies API calls to `NEXT_PUBLIC_API_BASE_URL`. When running locally without Nginx, set it to `http://localhost:8000`.

## 5. Production Deployment

### Process Model
- **FastAPI** via `uvicorn` behind systemd (`/etc/systemd/system/scope-backend.service`).
- **Next.js** production build via `npm run build` + `npm run start` (also systemd), or containerize both.
- **Nginx** handles TLS (Let’s Encrypt / Certbot) and routes:
  - `/` → Next.js (`127.0.0.1:3300`)
  - `/backend/` → FastAPI (`127.0.0.1:8010`)

Example Nginx server block:

```nginx
server {
  listen 80;
  server_name scope.thinkbot.app;
  location /.well-known/acme-challenge/ { root /var/www/html; }
  location / { return 301 https://$host$request_uri; }
}

server {
  listen 443 ssl http2;
  server_name scope.thinkbot.app;

  ssl_certificate /etc/letsencrypt/live/scope.thinkbot.app/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/scope.thinkbot.app/privkey.pem;

  location /backend/ {
    proxy_pass http://127.0.0.1:8010/;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $remote_addr;
    proxy_set_header X-Forwarded-Proto https;
  }

  location / {
    proxy_pass http://127.0.0.1:3300/;
    proxy_set_header Host $host;
    proxy_set_header X-Forwarded-For $remote_addr;
    proxy_set_header X-Forwarded-Proto https;
  }
}
```

Run Certbot against this block: `sudo certbot --nginx -d scope.thinkbot.app`.

After deployment you can hit `/system/providers` to verify Supabase connectivity:

```bash
curl -s https://scope.thinkbot.app/backend/system/providers | jq
```

Expect `auth.status` and `storage.status` to read `"ok"`.

### Systemd Service Samples

`/etc/systemd/system/scope-backend.service`
```ini
[Unit]
Description=Scope Doc Backend
After=network.target

[Service]
User=scope
WorkingDirectory=/opt/scope_doc_gen/server
EnvironmentFile=/opt/scope_doc_gen/server/.env
ExecStart=/opt/scope_doc_gen/venv/bin/uvicorn server.api:app --host 127.0.0.1 --port 8010 --workers 2
Restart=always

[Install]
WantedBy=multi-user.target
```

`/etc/systemd/system/scope-frontend.service`
```ini
[Unit]
Description=Scope Doc Frontend
After=network.target

[Service]
User=scope
WorkingDirectory=/opt/scope_doc_gen/frontend
EnvironmentFile=/opt/scope_doc_gen/frontend/.env.local
ExecStart=/usr/bin/npm run start -- --hostname 127.0.0.1 --port 3300
Restart=always

[Install]
WantedBy=multi-user.target
```

Reload systemd and enable services:
```bash
sudo systemctl daemon-reload
sudo systemctl enable --now scope-backend scope-frontend
```

## 6. Supabase Smoke Test (Manual)
1. Sign in with an existing Supabase user (or create via Supabase Auth dashboard).
2. Create a project in the dashboard.
3. Upload an input document.
4. Launch a run (full mode, quick research).
5. Wait for completion → verify run steps, artifacts (rendered doc preview), and download works.
6. Visit `/search`, run a query that should hit the new artifact.
7. Confirm Supabase bucket contains the uploaded inputs and generated artifacts.

Automating these steps is tracked separately (`phase4-smoke`).

See `docs/smoke_test.md` for the detailed checklist.

---

This document intentionally focuses on Supabase. For a local-only install set `AUTH_PROVIDER=local` and `STORAGE_PROVIDER=local`, leave Supabase variables empty, and skip the bucket configuration; the remaining steps still apply.

